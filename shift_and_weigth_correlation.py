# -*- coding: utf-8 -*-
"""SHIFT AND WEIGTH CORRELATION

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DVAX0I12nN34LCtPWn_DuwZU4YNk1GSx
"""

## The current algorithm will be created in order to examine the relation
## between the shift and the measurements if there is any. The datasets that
## are going to be used will be find in the following path:
## /content/drive/Shareddrives/SCIRCULA TEAM/DATA SCIENCE/TECHNICAL FOLDER/
## WEIGHT ALLOCATION OPTIMIZATION/INITIAL TECHNICAL TEST FOR WEIGHT IDENTIFYING /TESTING CUSTOMERS.csv
## which is the dataset for the customer measurements, and the second one is the following:
## /content/drive/Shareddrives/SCIRCULA TEAM/DATA SCIENCE/TECHNICAL FOLDER/WEIGHT ALLOCATION OPTIMIZATION/
## INITIAL TECHNICAL TEST FOR WEIGHT IDENTIFYING /NIGHTIRE COMPANY INITIAL DATASET FOR WEIGHT ALLOCATION.csv
## which is the dataset for the garment measurements for the nightire company 




## importing the libraries needed
import pandas as pd
import numpy as np
from numpy import nan
from sklearn.linear_model import LinearRegression
from sklearn import linear_model
import statsmodels.api as sm
import statistics
from statistics import stdev
from scipy.stats import pearsonr
from scipy.stats import spearmanr

#READ THE DATASET NEEDED
## We are again going to use the same dataset again in terms of compasison sake.
nightire_data= pd.read_csv('/content/drive/Shareddrives/SCIRCULA TEAM/DATA SCIENCE/TECHNICAL FOLDER/WEIGHT ALLOCATION OPTIMIZATION/INITIAL TECHNICAL TEST FOR WEIGHT IDENTIFYING /NIGHTIRE COMPANY INITIAL DATASET FOR WEIGHT ALLOCATION.csv', 
                           header=0, names=['BUST','WAIST', 'HIPS', 'THIGHS', 'STRETCH', 'FABRIC'])
## print(nightire_data)

## Second dataset that we are going to need
## Remember: Here we want to calculate the correlation between the shift and the measurements
## The shift is the difference between the actual garment  measurements and the clients measurements
## Therefore the next dataset that we are going to need is about the customers measurements
customer_measurements=pd.read_csv('/content/drive/Shareddrives/SCIRCULA TEAM/DATA SCIENCE/TECHNICAL FOLDER/WEIGHT ALLOCATION OPTIMIZATION/INITIAL TECHNICAL TEST FOR WEIGHT IDENTIFYING /CUSTOMERS TESTING DATA.xlsx.csv',
                                  header=0, names=['BUST', 'WAIST', 'HIPS', 'THIGHS'])
## print(customer_measurements)

## creating all our garment types as indexes for the first dataset
nightire_data.index= ['BEAUTIFUL BODIES SHORT SLEEPWEAR', 'BEAUTIFUL BODIES LONG SLEEPWEAR', 'BLUE MIDI SET',
                       'BLUE BOXER SHORTS', 'BLUE MIDI BAMBOO SLEEPWEAR','CORAL COOLNESS SHORT SET',
                       'LOBSTER BAMBOO MIDI SET', 'LOBSTER MALE BOXER SHORTS','MALE-BOXER SLEEP SHORTS',
                       'BEVERLY HILLS SHORT SLEEPWEAR', 'NEW JUNGLE CATS LONG SLEEPWEAR', 'NO-MONDAY BLUES LONG SLEEPWEAR',
                       'PRINTED MIDI SLEEPWEAR SET', 'SWEET CLEMENTINE SHORT SET', 'THE NUTCRACKER LONG SLEEPWEAR', 'WILD CHRISTMAS BOXER SHORT']

## print(nightire_data)

## creating the names of the users as indexes for the second dataset
customer_measurements.index= ['NINA','CECILLIE','PENNY','PETE']

## printing the outcome
## print(customer_measurements)

## We are again going to get dummies for the fabric variable
## We cannot work with categorical variables like the fabric
## therefore we have to make these categorical variables into 
## numeric variables, to make the calculations much easier.

pd.get_dummies(nightire_data, columns=['FABRIC'])

## The NaN variables that we have are going to cause us problems 
## in the calculations, therefore we are going to replace the nan
## variables with zeros. 
## For the first dataset of the garment datasets we are going to
## do the following calculations

num_missing = (nightire_data[['BUST']] == nan).sum()
## report the results
## print(num_missing)
nightire_data[['BUST']] = nightire_data[['BUST']].replace(nan, 0)
## print(nightire_data)

## For the scond dataset of the customer testing data we do the same calculations:

num_missing= (customer_measurements[['BUST']]== nan).sum()
## report the results 
## print(num_missing)
customer_measurements[['BUST']] = customer_measurements[['BUST']].replace(nan, 0)
## print(customer_measurements)

## Now we have to calculate the shift for dataset 
## The shift is basically the variable that shows you were which the 
## size is going to be eventually. For example if the algorithm has decided
## that the size of the customer will be medium then comes the shift and tells 
## you if indeed the recommended size should eventually be medium or not.
## So we have calculated the shift for all the measurements, all the volunteers
## and all the types of garment that we have, we did those calculations in a different 
## file which we are going to import right away

shift_data = pd.read_csv('/content/drive/Shareddrives/SCIRCULA TEAM/DATA SCIENCE/TECHNICAL FOLDER/WEIGHT ALLOCATION OPTIMIZATION/INITIAL TECHNICAL TEST FOR WEIGHT IDENTIFYING /SHIFT CALCULATIONS.csv',
                         header=0, names=['SHIFT BUST NINA', 'SHIFT WAIST NINA', 'SHIFT HIPS NINA', 'SHIFT THIGS NINA',
                                          'SHIFT BUST CECILLIE', 'SHIFT WAIST CECILLIE', 'SHIFT HIPS CECEILLIE', 'SHIFT THIGHS CECEILLIE',
                                          'SHIFT BUST PENNY', 'SHIFT WAIST PENNY', 'SHIFT HIPS PENNY', 'SHIFT THIGHS PENNY', 
                                          'SHIFT WAIST PETE', 'SHIFT HIPS PETE', 'SHIFT THIGHS PETE'])
shift_data.idex = (0, 15)
## reporting the results
## print(shift_data)

## Now we are going to see if the shift and the measurements are
## correlated in any way, so we are going to chck that through 
## a pearson's and spearman's test, we are going to take


shift= shift_data['SHIFT WAIST CECILLIE']
bust= nightire_data['BUST']

## in order to make the correlations I need the mean and the 
## standard deviation of the dataset


shift_mean = statistics.mean(shift)
bust_mean = statistics.mean(bust)
print(' The mean of the shift is:', shift_mean)
print(' The mean of the bust is:', bust_mean)


shift_standard_deviation = stdev(shift)
bust_standard_deviation = stdev(bust)
print(' The standard deviation of the shift is:', shift_standard_deviation)
print('The standard deviation of the bust is:', bust_standard_deviation)

## prepearing the data 
data1 = 1.09 * shift + 31 ##(1.09 and 31 are the mean and the standard deviation respectively). 
data2 = data1 + (23 * bust + 36.75)
corr, _ = pearsonr(shift, bust)
print('Pearsons correlation: %.3f' % corr)
## The results are reasonable because we have used those measurements to calulate  the shift

## This is an alternative way of examining the corelation
corr, _ = spearmanr(shift, bust)
print('Spearmans correlation: %.3f' % corr)